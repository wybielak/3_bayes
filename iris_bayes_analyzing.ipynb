{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fcd60b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "\n",
    "import pylab\n",
    "\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9dffe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessing:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def shuffling(self, data_list):\n",
    "        n = len(data_list)-1\n",
    "\n",
    "        for i in range(n,-1,-1):\n",
    "            index = random.randint(0,i)\n",
    "            tmp = data_list.loc[i]\n",
    "            data_list.loc[i] = data_list.loc[index]\n",
    "            data_list.loc[index] = tmp\n",
    "    \n",
    "    def normalize(self, data_list):\n",
    "        for col in data_list.columns:\n",
    "            if type(data_list[col].loc[0]) is not type(\"text\"):\n",
    "                min1 = float(\"inf\")\n",
    "                max1 = float(\"-inf\")\n",
    "\n",
    "                for x in data_list[col]:\n",
    "                    min1 = min(min1,x)\n",
    "                    max1 = max(max1,x)\n",
    "                    \n",
    "                for i in range(len(data_list[col])):\n",
    "                    data_list.at[i, col] -= min1  \n",
    "                    data_list.at[i, col] /= (max1 - min1)\n",
    "\n",
    "    def train_test_split(self, data_list):\n",
    "        train_len = round((len(data_list)-1) * 0.7)\n",
    "        test_len = round((len(data_list)-1) * 0.3)\n",
    "        \n",
    "        train = data_list[0:train_len]\n",
    "        test = data_list[train_len:len(data_list)]\n",
    "\n",
    "        test = test.reset_index(drop=True) #resetowanie indeksacji dataframeu\n",
    "\n",
    "        return train, test\n",
    "    \n",
    "    def label_split(self, data_list):\n",
    "        feature_list = []\n",
    "        label_list = []\n",
    "\n",
    "        sum = 0\n",
    "        for col in data_list.columns:\n",
    "            if type(data_list[col].loc[0]) is not type(\"text\"):\n",
    "                sum +=1\n",
    "        \n",
    "        for i in range(len(data_list)):\n",
    "            feature_list.append(data_list.loc[i].to_list()[:sum])\n",
    "\n",
    "        for i in range(len(data_list)):\n",
    "            label_list.append(data_list.loc[i].to_list()[sum:])\n",
    "        \n",
    "        return feature_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "469463ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussInator(x, mi, sigma):\n",
    "    \n",
    "    return (1 / (sigma * math.sqrt(2 * math.pi))) * math.exp(-((x - mi) ** 2) / (2 * sigma ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74edf072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(d_list, t_data): # dla kazdej cechy dla kazdego gatunky srednia i odchylenie, 12 srednich i odchylen, dla sprawdzanego podstawiamy wzor, iloczyn wektorowy\n",
    "\n",
    "    dtp = DataProcessing()\n",
    "    cat_avg_dict = {} # dict na średnie z podziałem kategoria {cechy}\n",
    "    cat_elem_len = {} # dict na ilość elementów dla każdej cechy\n",
    "    cat_std_dict = {} # dict na odchylenia\n",
    "\n",
    "    inator_dict = {} # dict na wyliczone wartości gęstości dla każdej cechy\n",
    "\n",
    "    product_per_cat = {} # dict z kategoriami i iloczynami cech dla każdej kategorii\n",
    "\n",
    "    feature_list, label_list = dtp.label_split(d_list)\n",
    "\n",
    "    sum = 0\n",
    "    for col in d_list.columns:\n",
    "        if type(d_list[col].loc[0]) is not type(\"text\"): # ilość kolumn które opisują cechy nie kategorie\n",
    "            sum +=1\n",
    "\n",
    "    for label in label_list: # ustawianie dict'ów aby były podzielone na kategorie\n",
    "        cat_avg_dict[label[0]] = {}\n",
    "        cat_elem_len[label[0]] = {}\n",
    "        cat_std_dict[label[0]] = {}\n",
    "        inator_dict[label[0]] = {}\n",
    "        product_per_cat[label[0]] = 1\n",
    "        for col in d_list.columns[:sum]: # ustawianie dict'ów aby był podział na cechy dla każdej kategorii\n",
    "            cat_avg_dict[label[0]][col] = 0\n",
    "            cat_elem_len[label[0]][col] = 0\n",
    "            cat_std_dict[label[0]][col] = 0\n",
    "            inator_dict[label[0]][col] = 1\n",
    "    \n",
    "\n",
    "    for i, label in enumerate(label_list): # obliczanie sumy i ilości elementów dla każdej cechy\n",
    "        if d_list.loc[i]['variety'] is label[0]:\n",
    "            for col in d_list.columns[:sum]:\n",
    "                    cat_avg_dict[label[0]][col] += d_list.loc[i][col]\n",
    "                    cat_elem_len[label[0]][col] += 1\n",
    "\n",
    "    for cat in cat_avg_dict: # obliczanie średniej przez dzielenie dla każdej cechy\n",
    "        for elem in cat_avg_dict[cat]:\n",
    "            cat_avg_dict[cat][elem] /= cat_elem_len[cat][elem]\n",
    "\n",
    "    for i, label in enumerate(label_list): # obliczanie sumy odchylenia standardowego\n",
    "        if d_list.loc[i]['variety'] is label[0]:\n",
    "            for col in d_list.columns[:sum]:\n",
    "                    cat_std_dict[label[0]][col] += (d_list.loc[i][col] - cat_avg_dict[label[0]][col])**2\n",
    "\n",
    "    for cat in cat_avg_dict:\n",
    "        for elem in cat_avg_dict[cat]: # obliczanie iloczynu i pierwiastka i mamy odchylenie\n",
    "             cat_std_dict[cat][elem] /= cat_elem_len[cat][elem]\n",
    "             cat_std_dict[cat][elem] = math.sqrt(cat_std_dict[cat][elem])\n",
    "\n",
    "    for cat in cat_avg_dict: # wartości gęstości dla testowanego rekordu\n",
    "        for i, elem in enumerate(cat_avg_dict[cat]):\n",
    "            inator_dict[cat][elem] = gaussInator(t_data[i], cat_avg_dict[cat][elem], cat_std_dict[cat][elem])\n",
    "\n",
    "    for cat in cat_avg_dict:\n",
    "        for elem in cat_avg_dict[cat]: # końcowy iloraz wszystkich cech dla kategorii\n",
    "            product_per_cat[cat] *= inator_dict[cat][elem]\n",
    "\n",
    "    max_cat = \"\"\n",
    "    tmp = float(\"-inf\")\n",
    "\n",
    "    for cat in product_per_cat: # wybieranie kategorii z maksymalnym ilorazem\n",
    "        if product_per_cat[cat] >= tmp:\n",
    "             tmp = product_per_cat[cat]\n",
    "             max_cat = cat\n",
    "\n",
    "    return max_cat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20b481df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c6eea257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(data)) # dlugosc datasetu\n",
    "#print(data.loc[5]) # uzyskiwanie danych o jednym rekordzie\n",
    "#print(data.loc[5].to_list()) # wypisywanie rekordu w postaci listy\n",
    "\n",
    "#sb.pairplot(data, hue=\"variety\") # wyswietlanie wykresow kazdej cechy\n",
    "#sb.violinplot(data, x=\"sepal.width\", y=\"variety\", inner=\"quartile\")\n",
    "#print(data.describe()) # wypisuje uśrednione info o datasecie\n",
    "#print(data)\n",
    "\n",
    "#x = []\n",
    "#for i in range(0,100,1):\n",
    "#    x.append(i/10)\n",
    "\n",
    "#y = []\n",
    "#for e in x:\n",
    "#    y.append(gaussInator(e,5,1))\n",
    "\n",
    "#pylab.plot(x, y)\n",
    "#pylab.title('Wykres f(x) = a*x - b')\n",
    "#pylab.grid(True)\n",
    "#pylab.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee7810de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtp = DataProcessing()\n",
    "\n",
    "dtp.shuffling(data)\n",
    "dtp.normalize(data)\n",
    "train_data, test_data = dtp.train_test_split(data)\n",
    "\n",
    "#print(train_data)\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea6799e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(naiveBayes(train_data, (6.4, 3.1, 5.5, 1.8))) # virginica bez normalizacji\n",
    "#train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62c5b729-a67c-40a8-9c07-e32540adcd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naiwny klasyfikator Bayesa\n",
      "All: 45, good: 44, bad: 1\n",
      "Test statistic: 97.78%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all=0\n",
    "good=0\n",
    "bad=0\n",
    "\n",
    "for i in range(len(test_data)-1):\n",
    "\n",
    "    result = naiveBayes(train_data, test_data.loc[i].to_list()[:4])\n",
    "\n",
    "    if result == test_data.loc[i].to_list()[4:][0]:\n",
    "        good += 1\n",
    "    else:\n",
    "        bad += 1\n",
    "\n",
    "    all += 1\n",
    "\n",
    "print(\"Naiwny klasyfikator Bayesa\")\n",
    "print(f\"All: {all}, good: {good}, bad: {bad}\")\n",
    "print(f\"Test statistic: {round(good/all,4)*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
